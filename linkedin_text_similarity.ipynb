{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linkedin_text_similarity.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPk9EnXj7iQBuuSIhyQMkKI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plchuaa/gordonchu/blob/master/linkedin_text_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYzL6k2PR2WF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X37dQsGcR8Lh",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing by get text from json by some simple cleaning and store at a dataframe for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvnHm6chRtl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_cleaning(text):\n",
        "    if len(text) > 0:\n",
        "        text = text[0]\n",
        "        text = re.sub(r\"\\\\n\", \" \", text)\n",
        "        # text = re.sub(r\"\\.\\.\\.\", \" \", text)\n",
        "        text = re.sub(r\"\\.+\\.+\", \" \", text)\n",
        "        text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "        text = remove_emoji(text)\n",
        "        text = remove_url(text)\n",
        "        text = remove_newline(text)\n",
        "    else:\n",
        "        text = \"\"\n",
        "    return text\n",
        "\n",
        "\n",
        "def get_name(json_dictionairy):\n",
        "    data = json_dictionairy[\"current\"][0]\n",
        "    name = re.findall(r'(?:\\n +)([\\S\\s]+)(?:\\n +Status is)', data)\n",
        "    name = text_cleaning(name)\n",
        "    return name\n",
        "\n",
        "\n",
        "def get_info(json_dictionairy):\n",
        "    data = json_dictionairy[\"current\"][0]\n",
        "    info = re.findall(r'(?:See contact info(?:\\n +)*[a-z0-9 A-Z+]+(?:\\n +)*)([\\s\\S]+)', data)\n",
        "    info = text_cleaning(info)\n",
        "    return info\n",
        "\n",
        "\n",
        "def get_summary(json_dictionairy):\n",
        "    data = json_dictionairy[\"summary\"]\n",
        "    summary = text_cleaning(data)\n",
        "    return summary\n",
        "\n",
        "\n",
        "def list_cleaning(data):\n",
        "    lists = []\n",
        "    for exp in data:\n",
        "        if isinstance(exp, list):\n",
        "            for e in exp:\n",
        "                lists.append(text_cleaning([e]))\n",
        "        else:\n",
        "            lists.append(text_cleaning([exp]))\n",
        "\n",
        "    return (\" \").join(lists) if len(lists) > 0 else \"\"\n",
        "\n",
        "\n",
        "def get_experience(json_dictionairy):\n",
        "    data = json_dictionairy[\"experience\"]\n",
        "    experience = list_cleaning(data)\n",
        "    return experience\n",
        "\n",
        "\n",
        "def get_education(json_dictionairy):\n",
        "    data = json_dictionairy[\"education\"]\n",
        "    education = list_cleaning(data)\n",
        "    return education\n",
        "\n",
        "\n",
        "def get_license(json_dictionairy):\n",
        "    data = json_dictionairy[\"licenses\"]\n",
        "    licenses = list_cleaning(data)\n",
        "    return licenses\n",
        "\n",
        "\n",
        "def get_skill(json_dictionairy):\n",
        "    data = json_dictionairy[\"skills\"]\n",
        "    skills = list_cleaning(data)\n",
        "    return skills\n",
        "\n",
        "\n",
        "def get_tech(json_dictionairy):\n",
        "    data = json_dictionairy[\"tech\"]\n",
        "    tech = list_cleaning(data)\n",
        "    return tech\n",
        "\n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "def remove_url(text):\n",
        "    text = re.sub(r'[a-zA-z]+://[^\\s]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'[a-zA-Z]+(\\.[a-zA-Z]+)+', '', text, flags=re.MULTILINE)\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_newline(text):\n",
        "    text = re.sub(r\"\\n\", \" \", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Text Preprocessing(remove stopwords,punctuations).\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "# build a list of stopwords to use to filter\n",
        "stopwords = list(STOP_WORDS)\n",
        "stopwords.append(\"see more\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3t3gmEkSVwp",
        "colab_type": "code",
        "outputId": "f45c9f87-8046-4eb1-b0c1-95d8dacd73c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Get data from drive\n",
        "drive.mount('/content/drive',force_remount=False)\n",
        "os.chdir(\"/content/drive/My Drive/\")\n",
        "\n",
        "\n",
        "# Or change os.scandir('path-to-the-linkedin-dataset')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rKsw_qi9zZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "profile_df  = pd.DataFrame(columns=[\"profile_name\",\"profile_detail\", \"profile_info\",\"profile_summary\",\"profile_experience\",\n",
        "                                         \"profile_education\",\"profile_license\",\"profile_skill\",\"profile_tech\"])\n",
        "\n",
        "with os.scandir('./linkedin/') as entries:\n",
        "    for each in entries:\n",
        "        file = open(each, 'r', encoding=\"utf-8\")\n",
        "        profile_data = json.load(file)\n",
        "\n",
        "        profile_name = get_name(profile_data)\n",
        "        profile_info = get_info(profile_data)\n",
        "        profile_summary = get_summary(profile_data)\n",
        "        profile_experience = get_experience(profile_data)\n",
        "        profile_education = get_education(profile_data)\n",
        "        profile_license = get_license(profile_data)\n",
        "        profile_skill = get_skill(profile_data)\n",
        "        profile_tech = get_tech(profile_data)\n",
        "        profile_detail = profile = profile_info + profile_summary + profile_experience + profile_education + profile_license + profile_skill + profile_tech\n",
        "\n",
        "        profile_to_row = {}\n",
        "        profile_to_row[\"profile_name\"] = profile_name\n",
        "        profile_to_row[\"profile_info\"] = profile_info\n",
        "        profile_to_row[\"profile_summary\"] = profile_summary\n",
        "        profile_to_row[\"profile_experience\"] = profile_experience\n",
        "        profile_to_row[\"profile_education\"] = profile_education\n",
        "        profile_to_row[\"profile_skill\"] = profile_skill\n",
        "        profile_to_row[\"profile_license\"] = profile_license\n",
        "        profile_to_row[\"profile_tech\"] = profile_tech\n",
        "        profile_to_row[\"profile_detail\"] = profile_detail\n",
        "\n",
        "        profile_df = profile_df.append(profile_to_row, ignore_index=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi6wLnN3fRQD",
        "colab_type": "code",
        "outputId": "0e55c898-b4cc-4bd2-baba-cef38bf1cfbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        }
      },
      "source": [
        "profile_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>profile_name</th>\n",
              "      <th>profile_detail</th>\n",
              "      <th>profile_info</th>\n",
              "      <th>profile_summary</th>\n",
              "      <th>profile_experience</th>\n",
              "      <th>profile_education</th>\n",
              "      <th>profile_license</th>\n",
              "      <th>profile_skill</th>\n",
              "      <th>profile_tech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abby Tang</td>\n",
              "      <td>Business Strategist skilled in Joint Marketing...</td>\n",
              "      <td>Business Strategist skilled in Joint Marketing...</td>\n",
              "      <td>Business Strategist skilled in Joint Marketin...</td>\n",
              "      <td>APCJ Director, Cloud Field Operations Company...</td>\n",
              "      <td>University of California, Irvine Degree Name ...</td>\n",
              "      <td></td>\n",
              "      <td>Business Alliances   Go-to-market Strategy   ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ai Shinozaki</td>\n",
              "      <td>My nick name is Ai Shinozaki. I am a PG Girl S...</td>\n",
              "      <td>My nick name is Ai Shinozaki. I am a PG Girl S...</td>\n",
              "      <td>My nick name is Ai Shinozaki. I am a PG Girl ...</td>\n",
              "      <td>PG Model Company Name ABC PG Model Dates Empl...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Target Orientation   Reading Comprehension   ...</td>\n",
              "      <td>Other Skills Sexy PG Show Sexy Girl Face &amp; Bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dr Alan Chow MIET MIEEE MAUSIMM</td>\n",
              "      <td>Founder of a disruptive project with strong Gl...</td>\n",
              "      <td>Founder of a disruptive project with strong Gl...</td>\n",
              "      <td>Founder of a disruptive project with strong G...</td>\n",
              "      <td>Chairman, Investment Committee Company Name C...</td>\n",
              "      <td>Renmin University of China Degree Name Doctor...</td>\n",
              "      <td></td>\n",
              "      <td>Investments   Private Equity   Corporate Fina...</td>\n",
              "      <td>Industry Knowledge Equities See 25 endorsemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abel Cheung</td>\n",
              "      <td>Administrator in a variety of coorporate netwo...</td>\n",
              "      <td>Administrator in a variety of coorporate netwo...</td>\n",
              "      <td>Administrator in a variety of coorporate netw...</td>\n",
              "      <td>Network Architect Company Name Next Media Ani...</td>\n",
              "      <td>AccessData BootCamp &amp; FTK training Field Of S...</td>\n",
              "      <td>Novell Certified Linux Administrator (Novell ...</td>\n",
              "      <td>Linux   Apache   Ubuntu</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ai autodata</td>\n",
              "      <td>Managing Director Company Name</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Managing Director Company Name</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Xin LI</td>\n",
              "      <td>I am a second-year . student at CUHK. Prior to...</td>\n",
              "      <td>I am a second-year . student at CUHK. Prior to...</td>\n",
              "      <td>I am a second-year . student at CUHK. Prior t...</td>\n",
              "      <td>Research Intern, NLP Group@Tencent AI Lab Com...</td>\n",
              "      <td>Field Of Study Faculty of Engineering Dates ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Wong Loretta</td>\n",
              "      <td>Company Name Google Total Duration 4 yrs 3 m...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Company Name Google Total Duration 4 yrs 3 mo...</td>\n",
              "      <td>The University of Hong Kong Degree Name Bache...</td>\n",
              "      <td></td>\n",
              "      <td>Marketing Strategy   Search Engine Technology...</td>\n",
              "      <td>Industry Knowledge Business Strategy See 3 en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Worldmoney Blockchain News</td>\n",
              "      <td>Company Name Worldmoney Blockchain Financial...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Company Name Worldmoney Blockchain Financial ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Wayne Liu</td>\n",
              "      <td>Technology professional with 10 years experien...</td>\n",
              "      <td>Technology professional with 10 years experien...</td>\n",
              "      <td>Technology professional with 10 years experie...</td>\n",
              "      <td>Technology Specialist Company Name 3Revolutio...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Digital Printing   Color Management   Printer...</td>\n",
              "      <td>Industry Knowledge R&amp;D See 2 endorsements for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Ray (Wen Jie) LIEW</td>\n",
              "      <td>Ray Liew is the Data and AI solution specialis...</td>\n",
              "      <td>Ray Liew is the Data and AI solution specialis...</td>\n",
              "      <td>Ray Liew is the Data and AI solution speciali...</td>\n",
              "      <td>Data and AI Solution Specialist (SSP) Company...</td>\n",
              "      <td>HKUST Business School Degree Name Bachelor of...</td>\n",
              "      <td>Insight Selling Issued date and, if applicabl...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        profile_name  ...                                       profile_tech\n",
              "0                          Abby Tang  ...                                                   \n",
              "1                       Ai Shinozaki  ...   Other Skills Sexy PG Show Sexy Girl Face & Bo...\n",
              "2    Dr Alan Chow MIET MIEEE MAUSIMM  ...   Industry Knowledge Equities See 25 endorsemen...\n",
              "3                        Abel Cheung  ...                                                   \n",
              "4                        ai autodata  ...                                                   \n",
              "..                               ...  ...                                                ...\n",
              "95                            Xin LI  ...                                                   \n",
              "96                      Wong Loretta  ...   Industry Knowledge Business Strategy See 3 en...\n",
              "97        Worldmoney Blockchain News  ...                                                   \n",
              "98                         Wayne Liu  ...   Industry Knowledge R&D See 2 endorsements for...\n",
              "99                Ray (Wen Jie) LIEW  ...                                                   \n",
              "\n",
              "[100 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4wWOm87jDci",
        "colab_type": "text"
      },
      "source": [
        "Possible direction:\n",
        "1. further split the profile into parts(info + summary, exp, tech+skill+license)\n",
        "\n",
        "2. modify ways to calculate similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLrVF0DDfRg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spacy tokenizer to remove stopwords and punctuation, lemma words\n",
        "def spacy_tokenizer(text):\n",
        "    parser = English()\n",
        "    mytokens = parser(text)\n",
        "    mytokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens]\n",
        "    mytokens = [word for word in mytokens if word not in stopwords]\n",
        "    mytokens = [word for word in mytokens if word.isalpha() or word.isnumeric() or len(word)>1 ]\n",
        "    # mytokens = [word for word in mytokens if word not in string.punctuation]\n",
        "    return mytokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvE24EJTEIMQ",
        "colab_type": "code",
        "outputId": "e76feedd-d342-498c-a50b-0f8b3333730b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "example1 = profile_df[\"profile_detail\"][0]\n",
        "example1 = spacy_tokenizer(example1)\n",
        "print(example1)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['business', 'strategist', 'skilled', 'joint', 'marketing', 'partner', 'management', 'market', 'strategy', 'channel', 'strategy', 'channel', 'sales', 'developer', 'background', 'strong', 'business', 'development', 'professional', 'bs', 'focused', 'information', 'computer', 'science', 'university', 'california', 'irvine', 'business', 'strategist', 'skilled', 'joint', 'marketing', 'partner', 'management', 'market', 'strategy', 'channel', 'strategy', 'channel', 'sales', 'developer', 'background', 'strong', 'business', 'development', 'professional', 'bs', 'focused', 'information', 'computer', 'science', 'university', 'california', 'irvine', 'apcj', 'director', 'cloud', 'field', 'operations', 'company', 'f5', 'networks', 'dates', 'employed', 'feb', '2019', 'present', 'employment', 'duration', '3', 'mos', 'location', 'hong', 'kong', 'global', 'alliance', 'partner', 'development', 'company', 'amazon', 'web', 'services', 'dates', 'employed', 'jan', '2018', 'feb', '2019', 'employment', 'duration', '1', 'yr', '2', 'mos', 'location', 'hong', 'kong', 'gm', 'greater', 'china', 'business', 'development', 'director', 'apac', 'japan', 'company', 'damballa', 'inc.', 'dates', 'employed', 'jan', '2015', 'nov', '2017', 'employment', 'duration', '2', 'yrs', '11', 'mos', 'location', 'hong', 'kong', 'accountable', 'growth', 'strategic', 'alliance', 'asia', 'pacific', 'developed', 'market', 'strategy', 'greater', 'china', 'philippines', 'strategic', 'alliance', 'apac', 'japan', 'company', 'juniper', 'networks', 'dates', 'employed', 'nov', '2003', '2014', 'employment', 'duration', '10', 'yrs', '7', 'mos', 'location', 'hong', 'kong', 'introduced', 'developed', 'strategic', 'partnerships', 'ibm', 'hp', 'technology', 'partners', 'solution', 'sr', 'manager', 'apac', 'japan', 'company', 'netscreen', 'juniper', 'dates', 'employed', 'nov', '2003', '2006', 'employment', 'duration', '2', 'yrs', '7', 'mos', 'location', 'hong', 'kong', 'developed', 'isp', 'partner', 'program', 'spokesperson', 'netscreen', 'juniper', 'handled', 'technology', 'researcher', 'relationships', 'including', 'gartner', 'frost', 'sullivan', 'product', 'manager', 'company', 'mcafee', 'dates', 'employed', 'sep', '1999', 'jan', '2003', 'employment', 'duration', '3', 'yrs', '5', 'mos', 'location', 'hong', 'kong', 'managed', 'team', 'pre', 'sales', 'engineers', 'north', 'asia', 'primarily', 'spokesperson', 'mcafee', 'managed', 'retail', 'commercial', 'products', 'asia', 'pacific', 'gauntlet', 'proxy', 'firewall', 'authentication', 'developer', 'company', 'trusted', 'information', 'systems', 'tis', 'mcafee', 'dates', 'employed', 'jan', '1997', 'sep', '1999', 'employment', 'duration', '2', 'yrs', '9', 'mos', 'location', 'greater', 'los', 'angeles', 'area', 'developed', 'number', 'proxies', 'gauntlet', 'firewall', 'worked', 'authentication', 'technology', 'partners', 'including', 'rsa', 'funk', 'vasco', 'enable', 'radius', 'gauntlet', 'software', 'engineer', 'company', 'smith', 'micro', 'software', 'inc.', 'dates', 'employed', 'dec', '1995', 'jan', '1997', 'employment', 'duration', '1', 'yr', '2', 'mos', 'developed', 'proprietary', 'encryption', 'algorithm', 'gui', 'developer', 'intranet', 'gm', 'greater', 'china', 'business', 'development', 'director', 'apac', 'japan', 'company', 'damballa', 'inc.', 'dates', 'employed', 'jan', '2015', 'nov', '2017', 'employment', 'duration', '2', 'yrs', '11', 'mos', 'location', 'hong', 'kong', 'strategic', 'alliance', 'apac', 'japan', 'company', 'juniper', 'networks', 'dates', 'employed', 'nov', '2003', '2014', 'employment', 'duration', '10', 'yrs', '7', 'mos', 'location', 'hong', 'kong', 'solution', 'sr', 'manager', 'apac', 'japan', 'company', 'netscreen', 'juniper', 'dates', 'employed', 'nov', '2003', '2006', 'employment', 'duration', '2', 'yrs', '7', 'mos', 'location', 'hong', 'kong', 'product', 'manager', 'company', 'mcafee', 'dates', 'employed', 'sep', '1999', 'jan', '2003', 'employment', 'duration', '3', 'yrs', '5', 'mos', 'location', 'hong', 'kong', 'gauntlet', 'proxy', 'firewall', 'authentication', 'developer', 'company', 'trusted', 'information', 'systems', 'tis', 'mcafee', 'dates', 'employed', 'jan', '1997', 'sep', '1999', 'employment', 'duration', '2', 'yrs', '9', 'mos', 'location', 'greater', 'los', 'angeles', 'area', 'software', 'engineer', 'company', 'smith', 'micro', 'software', 'inc.', 'dates', 'employed', 'dec', '1995', 'jan', '1997', 'employment', 'duration', '1', 'yr', '2', 'mos', 'university', 'california', 'irvine', 'degree', 'bs', 'field', 'study', 'information', 'computer', 'science', 'dates', 'attended', 'expected', 'graduation', '1993', '1995', 'business', 'alliances', 'market', 'strategy', 'cloud', 'computing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwFc0kOshzPg",
        "colab_type": "text"
      },
      "source": [
        "Different way to get similarity matrix \n",
        "\n",
        "**1. spacy_tokenizer + genism(tfidf)**\n",
        "\n",
        "2. spacy_tokenizer + sklearn tfidfvectorizer + cosine similarity\n",
        "\n",
        "3. spacy_tokenizer + spacy similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRmPoSCcyBej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# target_profile = input(\"something here: \")\n",
        "target_profile = \"My nick name is Ai Shinozaki. I am a PG Girl Show. I can make Sexy Walk show, Sexy Face Funny Show or whatever, I can speak Japanese, Mandarin and English. I love food, sports, music, movies. I like to travel and picnic to different countries.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHQ6b6vrPEo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pprint\n",
        "from gensim import corpora\n",
        "\n",
        "# Lowercase each document, split it by white space and filter out stopwords\n",
        "texts = [spacy_tokenizer(text) for text in profile_df[\"profile_detail\"]]\n",
        "\n",
        "# Count word frequencies\n",
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "# Only keep words that appear more than once\n",
        "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psTNMfpLzHyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = corpora.Dictionary(processed_corpus)\n",
        "pprint.pprint(dictionary.token2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaxV4zB-zLL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
        "pprint.pprint(bow_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9SPHSGsnX5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "print(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoeuhjlSnfXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import models\n",
        "\n",
        "tfidf = models.TfidfModel(corpus)\n",
        "corpus_tfidf = tfidf[corpus]\n",
        "for doc in corpus_tfidf:\n",
        "    print(doc) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp1Sw44yogG6",
        "colab_type": "code",
        "outputId": "52ac255f-b64c-4c6a-ce93-6ee492f423fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)  # initialize an LSI transformation\n",
        "corpus_lsi = lsi_model[corpus_tfidf] \n",
        "lsi_model.print_topics(2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.219*\"endorsements\" + 0.176*\"date\" + 0.149*\"marketing\" + 0.137*\"microsoft\" + 0.130*\"title\" + 0.124*\"issued\" + 0.121*\"data\" + 0.117*\"expiration\" + 0.116*\"endorsement\" + 0.113*\"sales\"'),\n",
              " (1,\n",
              "  '-0.308*\"date\" + 0.288*\"marketing\" + -0.221*\"credential\" + -0.219*\"issued\" + -0.209*\"expiration\" + 0.177*\"endorsements\" + -0.168*\"architect\" + -0.167*\"aws\" + -0.160*\"certified\" + -0.125*\"authority\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RizCvch8pE5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for doc, as_text in zip(corpus_lsi, profile_df[\"profile_detail\"]):\n",
        "    print(doc, as_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0incPm7pIAE",
        "colab_type": "code",
        "outputId": "dacbfd59-940f-437a-a3b6-8027d958029c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim import similarities\n",
        "index = similarities.MatrixSimilarity(lsi_model[corpus])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo_F18Xvs_Iz",
        "colab_type": "code",
        "outputId": "70392a73-ee76-457d-9fe8-031faae420c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "index.save('/tmp/deerwester.index')\n",
        "index = similarities.MatrixSimilarity.load('/tmp/deerwester.index')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyk0y7ostibP",
        "colab_type": "code",
        "outputId": "60e7e67c-677f-47b3-a861-a3c2bee4239b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vec_bow = dictionary.doc2bow(spacy_tokenizer(target_profile))\n",
        "vec_lsi = lsi_model[vec_bow]  # convert the query to LSI space\n",
        "print(vec_lsi) # [(0, 4.325712071055434), (1, 0.10321814096913436)]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.22168110842854571), (1, 0.0981737243587752)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tszQLx93tRR2",
        "colab_type": "code",
        "outputId": "003bd03b-8f44-47fa-a94a-aa69041dc7eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
        "sims_list = list(enumerate(sims))\n",
        "print(sims_list)  # print (document_number, document_similarity) 2-tuples\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.99806106), (1, 0.9950665), (2, 0.9985498), (3, 0.54104465), (4, 0.7960783), (5, 0.9550155), (6, 0.99023056), (7, 0.99955654), (8, 0.99395895), (9, 0.6477216), (10, 0.9959041), (11, 0.9804049), (12, 0.33930454), (13, 0.86385715), (14, 0.99563074), (15, 0.95820314), (16, 0.9778053), (17, 0.554533), (18, 0.99995357), (19, 0.91056055), (20, 0.98761845), (21, 0.9772434), (22, 0.85976756), (23, 0.9966134), (24, 0.63619757), (25, 0.9917169), (26, 0.95649785), (27, 0.87727237), (28, 0.95951086), (29, 0.9875529), (30, 0.98838824), (31, 0.9999729), (32, 0.71629465), (33, 0.985718), (34, 0.99239904), (35, 0.5380999), (36, 0.8769004), (37, 0.96746606), (38, 0.86673975), (39, 0.9619413), (40, 0.97278064), (41, 0.94772995), (42, 0.9953339), (43, 0.9365268), (44, 0.99956244), (45, 0.978255), (46, 0.7930718), (47, 0.99293053), (48, 0.97106355), (49, 0.96086675), (50, 0.9997908), (51, 0.6801487), (52, 0.9321604), (53, 0.95811486), (54, 0.9984579), (55, 0.8978696), (56, 0.9980837), (57, 0.5889785), (58, 0.93300927), (59, 0.92980367), (60, 0.95123297), (61, 0.0), (62, 0.99950933), (63, 0.9968633), (64, 0.9708329), (65, 0.98886687), (66, 0.0), (67, 0.9335744), (68, 0.7151528), (69, 0.9769761), (70, 0.9766325), (71, 0.92734665), (72, 0.97089195), (73, 0.98658085), (74, 0.9924788), (75, 0.99850076), (76, 0.89916664), (77, 0.6505189), (78, 0.94457763), (79, 0.9082869), (80, 0.97614676), (81, 0.8993772), (82, 0.95824057), (83, 0.9999157), (84, 0.926798), (85, 0.9922092), (86, 0.9576679), (87, 0.41114417), (88, 0.9985385), (89, 0.77278835), (90, 0.9875215), (91, 0.24935058), (92, 0.98534113), (93, 0.99611616), (94, 0.79068565), (95, 0.9022436), (96, 0.982985), (97, 0.93284404), (98, 0.9895327), (99, 0.9429794)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqb_UZqbtUrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
        "sims"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2n4TnF8usMA",
        "colab_type": "code",
        "outputId": "125ebbbf-4b5f-43d5-e447-4c9f835772e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "print(\"Top 5 similar profile: \")\n",
        "for each in sims[0:5]:\n",
        "    print(each,profile_df[\"profile_detail\"][each[0]])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 5 similar profile: \n",
            "(31, 0.9999729)   CEO Company Name Fortel Solutions Limited Dates Employed Jan 2011 – Jun 2017 Employment Duration 6 yrs 6 mos Location Hong Kong   Director Company Name Orbrich (China) International Factors Limited Dates Employed Jan 2003 – Jul 2012 Employment Duration 9 yrs 7 mos Location Tianjin City, China Cofounder of Orbrich (China) International Factors. Responsibilities include overlooking the factoring operation and the credit decision and monitoring process and building the factoring risk management system See more See more   Senior Advisor Company Name Bain & Company Dates Employed Mar 2009 – Dec 2010 Employment Duration 1 yr 10 mos Location Beijing City, China Senior Advisor to Bain's Bank of China' IMM (Internal Market Model) Project See more   Senior Vice President Company Name American Bourses Corporation Dates Employed Aug 2000 – Dec 2002 Employment Duration 2 yrs 5 mos Location Singapore Responsible of business development of both online and offline financial solutions and financial services in North Asia Global Head of research and development in financial engineering. See more   Head of Quantitative Research Company Name Man Drapeau Research Dates Employed Aug 1998 – Jul 2000 Employment Duration 2 yrs Location Singapore Man Drapeau Research is a joint venture between Man Investment Products (UK) and Drapeau Advisors (US). Leading a team of finance engineers in devising risk management and portfolio strategies for the USD 300 million dollars of fund under management. The portfolio traded global financial and commodity futures and US stocks. See more   Lecturer Company Name National University of Singapore Dates Employed Sep 1993 – Jul 1998 Employment Duration 4 yrs 11 mos Location Singapore Department of Mathematics See more   Co-Founder & CEO Company Name  Limited Dates Employed Jul 2016 – Present Employment Duration 2 yrs 10 mos Location Hong Kong   Founder and President Company Name Hong Kong Blockchain Society Dates Employed Oct 2016 – Present Employment Duration 2 yrs 7 mos Location Hong Kong   Director Company Name Orbrich (China) International Factors Limited Dates Employed Jan 2003 – Jul 2012 Employment Duration 9 yrs 7 mos Location Tianjin City, China   Senior Advisor Company Name Bain & Company Dates Employed Mar 2009 – Dec 2010 Employment Duration 1 yr 10 mos Location Beijing City, China   Senior Vice President Company Name American Bourses Corporation Dates Employed Aug 2000 – Dec 2002 Employment Duration 2 yrs 5 mos Location Singapore   Head of Quantitative Research Company Name Man Drapeau Research Dates Employed Aug 1998 – Jul 2000 Employment Duration 2 yrs Location Singapore   Lecturer Company Name National University of Singapore Dates Employed Sep 1993 – Jul 1998 Employment Duration 4 yrs 11 mos Location Singapore  Cornell University Degree Name Doctor of Philosophy (.) Field Of Study Mathematics Dates attended or expected graduation 1986 – 1993   Stanford University Degree Name Master of Science (.) Field Of Study Mathematics Dates attended or expected graduation 1984 – 1986   Yale University Degree Name Bachelor of Arts (.) Field Of Study Mathematics Grade Honors in Mathematics Dates attended or expected graduation 1980 – 1984  Blockchain   Stochastic Calculus   Derivatives Modelling   Hedge Funds   Risk Management   Portfolio Management   Machine Learning   Big Data   Mathematical Modeling   Finance   Business Strategy   Investments   Start-ups   Management Consulting   Financial Modeling   Strategy   Strategic Planning   Financial Services   Business Development   Research   Management   Leadership   Financial Engineering   Bayesian statistics   Network Science   computational advertising   Probability Theory   Combinatorial Optimization   Dynamical Systems   Interest Rate Derivatives   Deep Learning   Boosting Trees   Natural Language Processing   Cryptography  Industry Knowledge Hedge Funds See 3 endorsements for Hedge Funds 3 Risk Management See 9 endorsements for Risk Management 9 Portfolio Management See 10 endorsements for Portfolio Management 10 Machine Learning See 3 endorsements for Machine Learning 3 Big Data See 2 endorsements for Big Data 2 Mathematical Modeling See 4 endorsements for Mathematical Modeling 4 Finance See 9 endorsements for Finance 9 Business Strategy See 5 endorsements for Business Strategy 5 Investments See 6 endorsements for Investments 6 Start-ups See 1 endorsement for Start-ups 1 Management Consulting See 1 endorsement for Management Consulting 1 Financial Modeling See 2 endorsements for Financial Modeling 2 Strategy See 2 endorsements for Strategy 2 Strategic Planning See 1 endorsement for Strategic Planning 1 Financial Services See 1 endorsement for Financial Services 1 Business Development See 1 endorsement for Business Development 1 Research See 3 endorsements for Research 3   Interpersonal Skills Management See 3 endorsements for Management 3 Leadership See 2 endorsements for Leadership 2   Other Skills Financial Engineering See 4 endorsements for Financial Engineering 4 Bayesian statistics See 1 endorsement for Bayesian statistics 1 Network Science See 1 endorsement for Network Science 1 computational advertising See 1 endorsement for computational advertising 1 Probability Theory See 2 endorsements for Probability Theory 2 Combinatorial Optimization See 1 endorsement for Combinatorial Optimization 1 Dynamical Systems See 2 endorsements for Dynamical Systems 2 Interest Rate Derivatives See 3 endorsements for Interest Rate Derivatives 3 Deep Learning See 1 endorsement for Deep Learning 1 Boosting Trees See 1 endorsement for Boosting Trees 1 Natural Language Processing See 1 endorsement for Natural Language Processing 1 Cryptography See 2 endorsements for Cryptography 2 \n",
            "(18, 0.99995357)   Product Marketing Manager Company Name Microsoft Dates Employed Nov 2016 – Present Employment Duration 2 yrs 6 mos   Consultant, Business Development Company Name Fuji Xerox (Hong Kong) Dates Employed Nov 2015 – Nov 2016 Employment Duration 1 yr 1 mo •\tResponsible for business development of Business Process Management and Marketing Solutions •\tDeveloped business strategy targeting to different customer segments •\tDefined the solution architecture, product positioning, pricing and messaging for the enterprise portfolio •\tIdentified solution partners with reliable solutions and professional technical support•\tBuilt and managed strategic relationships with key clients, agency partners and vendors•\tExecuted the launch plan and guided the sales team to translate leads into solid opportunities•\tDesigned marketing programs and events to reach new customers and generate sales leads •\tLed internal and client training sessions with relevant sales materials and sale pitching•\tConducted solution and product presentation and demonstrations to customers and partners•\tLeveraged other functional teams for cross selling of new products, . E-Form and Marketing Cloud See less See more   Marketing Executive Company Name Novation Solutions Limited Dates Employed Jan 2014 – Nov 2015 Employment Duration 1 yr 11 mos Location Kwun Tong - Assisted CCO in all marketing activities related to company transformation - Developed and implemented company re-branding and marketing plan - Managed the whole company website revamp and redesign project - Organized trade conferences and events for partners and customers See more See more   Sales Consultant Company Name Oracle Dates Employed Aug 2011 – Dec 2013 Employment Duration 2 yrs 5 mos Location Hong Kong - Responsible for Middleware, . web portal, content management tools - Coordinated and presented in large-scale events and seminars - Proposed best-fit product solution with sales demo kit and marketing material - Analyzed competitor products with differentiation of product features See more See more   Part time Project Officer Company Name Philips Dates Employed Jun 2009 – Mar 2011 Employment Duration 1 yr 10 mos Location Hong Kong   Consultant, Business Development Company Name Fuji Xerox (Hong Kong) Dates Employed Nov 2015 – Nov 2016 Employment Duration 1 yr 1 mo   Marketing Executive Company Name Novation Solutions Limited Dates Employed Jan 2014 – Nov 2015 Employment Duration 1 yr 11 mos Location Kwun Tong   Sales Consultant Company Name Oracle Dates Employed Aug 2011 – Dec 2013 Employment Duration 2 yrs 5 mos Location Hong Kong  The Chinese University of Hong Kong Degree Name Master of Social Science Field Of Study Corporate Communications Dates attended or expected graduation 2013 – 2015   The Chinese University of Hong Kong Degree Name Bachelor of Science (BSc) Field Of Study Systems Engineering Dates attended or expected graduation 2008 – 2011  Insight Selling Issuing authority Microsoft Issued date and, if applicable, expiration date of the certification or license Issued Sep 2017No Expiration Date  Product Marketing   Product Management   Cross-functional Team Leadership   Business Development   Marketing   Solution Selling   Competitive Analysis   Strategy   Consumer Electronics   Project Management   Account Management   Product Development   Business Strategy   CRM   Marketing Management   Cloud Computing   Marketing Communications   Strategic Planning   Market Research   Marketing Strategy   Microsoft Office   Microsoft Excel   PowerPoint   Microsoft Word   Enterprise Software   Leadership   Management   English   New Business Development  Industry Knowledge Business Development See 9 endorsements for Business Development 9 Marketing See 7 endorsements for Marketing 7 Solution Selling See 5 endorsements for Solution Selling 5 Competitive Analysis See 4 endorsements for Competitive Analysis 4 Strategy See 4 endorsements for Strategy 4 Consumer Electronics See 3 endorsements for Consumer Electronics 3 Project Management See 3 endorsements for Project Management 3 Account Management See 2 endorsements for Account Management 2 Product Development See 2 endorsements for Product Development 2 Business Strategy See 2 endorsements for Business Strategy 2 CRM See 2 endorsements for CRM 2 Marketing Management See 2 endorsements for Marketing Management 2 Cloud Computing See 2 endorsements for Cloud Computing 2 Marketing Communications See 1 endorsement for Marketing Communications 1 Strategic Planning See 1 endorsement for Strategic Planning 1 Market Research Marketing Strategy   Tools & Technologies Microsoft Office See 3 endorsements for Microsoft Office 3 Microsoft Excel See 2 endorsements for Microsoft Excel 2 PowerPoint See 2 endorsements for PowerPoint 2 Microsoft Word See 2 endorsements for Microsoft Word 2 Enterprise Software See 1 endorsement for Enterprise Software 1   Interpersonal Skills Leadership See 3 endorsements for Leadership 3 Management See 3 endorsements for Management 3   Languages English See 3 endorsements for English 3   Other Skills New Business Development See 8 endorsements for New Business Development 8 \n",
            "(83, 0.9999157) An Ex-KPMG consultant with Assurance and Financial Reporting training in Silicon Valley. Served in revenue management, finance, and operations roles. Passionate about strategy/BD, Revenue Management, Operations, B2B, O2O and Startups.  An Ex-KPMG consultant with Assurance and Financial Reporting training in Silicon Valley. Served in revenue management, finance, and operations roles. Passionate about strategy/BD, Revenue Management, Operations, B2B, O2O and Startups.  Business Planning Manager Company Name Microsoft Dates Employed 2016 – 2017 Employment Duration 1 yr   Analyst, Forecasting and Planning (Revenue Management and Analytics) Company Name The Walt Disney Company Dates Employed 2013 – 2016 Employment Duration 3 yrs + Supports the strategic and tactical objectives of the domestic parks and resorts by providing operational and financial forecasts of park attendance and admission revenue, room nights and resort revenue, merchandise and food & beverage revenue See more   Audit Assocaite Company Name KPMG Dates Employed 2007 – 2008 Employment Duration 1 yr Location Mountain View, California   International Business Operations Manager Company Name OKEx Dates Employed 2017 – Present Employment Duration 2 yrs   Analyst, Forecasting and Planning (Revenue Management and Analytics) Company Name The Walt Disney Company Dates Employed 2013 – 2016 Employment Duration 3 yrs  Northwestern University - Kellogg School of Management Field Of Study Modern Marketing: Content, Automation, and Analytics to Drive Growth   University of California, Los Angeles   Foothill College  SAS Enterprise Guide: ANOVA, Regression & Logistic Regression Issuing authority SAS   SAS Enterprise Guide: Advanced Task and Querying Issuing authority SAS  Accounting   Financial Reporting   Financial Analysis   Auditing   Financial Modeling   Business Strategy   Financial Accounting   Forecasting   Finance   GAAP   Sarbanes-Oxley Act   Pricing   General Ledger   Internal Controls   Corporate Finance   Data Analysis   Customer Experience   Microsoft Excel   Microsoft Office   Microsoft Word   Management   Teamwork   Critical Thinking  Industry Knowledge Auditing See 4 endorsements for Auditing 4 Financial Modeling See 3 endorsements for Financial Modeling 3 Business Strategy See 3 endorsements for Business Strategy 3 Financial Accounting See 3 endorsements for Financial Accounting 3 Forecasting See 2 endorsements for Forecasting 2 Finance See 2 endorsements for Finance 2 GAAP See 2 endorsements for GAAP 2 Sarbanes-Oxley Act See 1 endorsement for Sarbanes-Oxley Act 1 Pricing See 1 endorsement for Pricing 1 General Ledger See 1 endorsement for General Ledger 1 Internal Controls See 1 endorsement for Internal Controls 1 Corporate Finance See 1 endorsement for Corporate Finance 1 Data Analysis See 1 endorsement for Data Analysis 1 Customer Experience   Tools & Technologies Microsoft Excel See 3 endorsements for Microsoft Excel 3 Microsoft Office See 3 endorsements for Microsoft Office 3 Microsoft Word See 2 endorsements for Microsoft Word 2   Interpersonal Skills Management See 4 endorsements for Management 4 Teamwork Critical Thinking \n",
            "(50, 0.9997908) Business leader with 14 years of experience spanning Multinationals and Startups. Passionate about building new ventures and launching innovative products. Lived and worked across Asia, Europe and the US. Trilingual – English, Chinese and French.  Business leader with 14 years of experience spanning Multinationals and Startups. Passionate about building new ventures and launching innovative products. Lived and worked across Asia, Europe and the US. Trilingual – English, Chinese and French.  Business Development Director - APAC Company Name OST \"Simple Token\"​ Dates Employed Jun 2018 – Present Employment Duration 11 mos Location Hong Kong Strategic Partnerships with B2C companies interested in Blockchain and Tokenization. Sample industries include Gaming, Social Network, Fintech and Ecommerce. OST is a Tencent-backed blockchain startup and completed its ICO in 2017. We operate a full-stack SaaS platform that helps businesses launch and manage their own digital currencies. Potential benefits include better customer engagement, stronger growth and less reliance on third-party acquisition. See more Why OST is best positioned to deliver mass-market blockchain usage in 2019 Why OST is best positioned to deliver People of OST: Jean Wang, Business Development Director APAC People of OST: Jean Wang, Business Deve   Enterprise Solutions - HK Company Name Bloomberg LP Dates Employed 2017 – 2018 Employment Duration 1 yr Location Hong Kong Newsfeed Analytics using AI and NLP (natural language processing) See more   Business Development Director - APAC Company Name Dealogic Dates Employed 2015 – 2016 Employment Duration 1 yr Location Hong Kong Corporate Access and Investor Relations solutions See more   Singapore Country Manager Company Name Uzabase Dates Employed 2013 – 2015 Employment Duration 2 yrs Location Singapore  Joined before IPO as the first hire outside Japan  Launched the Singapore office and managed a team of 8 See more   Sales Director Company Name S&P Global Market Intelligence Dates Employed 2009 – 2013 Employment Duration 4 yrs Location Hong Kong, Singapore  Joined Capital IQ as the first local hire in Asia, and helped build the HK/China teams  Sales Team Leader for Greater China (2009-11) and Southeast Asia (2012-13) See more   Executive, Investment Banking - Greater China Company Name Macquarie Group Dates Employed 2007 – 2008 Employment Duration 1 yr Location Hong Kong   Associate, Investment Banking - Americas Company Name Barclays Investment Bank Dates Employed 2006 – 2007 Employment Duration 1 yr Location New York, USA   Telecom Engineer / Project Manager - Southern California Company Name AT&T Dates Employed 2001 – 2004 Employment Duration 3 yrs Location Los Angeles, USA   Business Development Director - APAC Company Name OST \"Simple Token\"​ Dates Employed Jun 2018 – Present Employment Duration 11 mos Location Hong Kong   Enterprise Solutions - HK Company Name Bloomberg LP Dates Employed 2017 – 2018 Employment Duration 1 yr Location Hong Kong   Business Development Director - APAC Company Name Dealogic Dates Employed 2015 – 2016 Employment Duration 1 yr Location Hong Kong   Singapore Country Manager Company Name Uzabase Dates Employed 2013 – 2015 Employment Duration 2 yrs Location Singapore   Sales Director Company Name S&P Global Market Intelligence Dates Employed 2009 – 2013 Employment Duration 4 yrs Location Hong Kong, Singapore  The University of Chicago Booth School of Business Degree Name Master of Business Administration (MBA) Dates attended or expected graduation 2004 – 2006   Caltech Degree Name Master of Science (MS) Field Of Study Electrical Engineering Dates attended or expected graduation 1999 – 2000   ESIEE PARIS Degree Name French Engineer's Degree Field Of Study Electrical Engineering Dates attended or expected graduation 1997 – 2000   Lycée Louis-le-Grand Degree Name French High School and Prep School Dates attended or expected graduation 1991 – 1997  Business Development   Management   Start-ups \n",
            "(44, 0.99956244) -Experiences of sales and marketing, account management and business alliances in software vendor, facing clients from HK, China, Taiwan, India, Japan, Malaysia, US and Europe, in different sectors, such as commercial, government and education-Management experiences in sales and marketing division-Experiences in closing global deals and have exposure in European countries, . UK, Germany, Netherlands, Belgium, France, Italy-Delivery of customer oriented products and services, rapid growth of client base from 35 to 600 clients in 6 years-Proven market development ability in new regions, Greater China Region, South East Asia Region-Leverage contacts with key industry players to promote product visibility and availability-Developed a different business model from direct sales in HK to channel sales in China, Malaysia, Taiwan, India and Japan market, from managing clients to managing partners -Proven track record in exploring, negotiating and closing mega deal in Asia Pacific Region Show less Show less of Ian’s summary  -Experiences of sales and marketing, account management and business alliances in software vendor, facing clients from HK, China, Taiwan, India, Japan, Malaysia, US and Europe, in different sectors, such as commercial, government and education-Management experiences in sales and marketing division-Experiences in closing global deals and have exposure in European countries, . UK, Germany, Netherlands, Belgium, France, Italy-Delivery of customer oriented products and services, rapid growth of client base from 35 to 600 clients in 6 years-Proven market development ability in new regions, Greater China Region, South East Asia Region-Leverage contacts with key industry players to promote product visibility and availability-Developed a different business model from direct sales in HK to channel sales in China, Malaysia, Taiwan, India and Japan market, from managing clients to managing partners -Proven track record in exploring, negotiating and closing mega deal in Asia Pacific Region  Head of Cloud Applications Company Name Oracle Dates Employed Feb 2018 – Present Employment Duration 1 yr 3 mos Location Hong Kong Oracle is the #1 provider of business software, with a broad portfolio of solutions for companies of all sizes. Today, 430,000 customers in 175 countries use Oracle technologies to seize business opportunities and solve real, tangible challenges. See more   Head of Cloud HCM Company Name SAP Dates Employed Sep 2015 – Feb 2018 Employment Duration 2 yrs 6 mos SAP is the world leader in enterprise applications in terms of software and software-related service revenue. Based on market capitalization, SAP is the world’s third largest independent software manufacturer. See more See more   Regional Sales Director Company Name SuccessFactors an SAP company Dates Employed Oct 2012 – Sep 2015 Employment Duration 3 yrs SuccessFactors, an SAP Company, is the leading provider of cloud-based business execution software, and delivers business alignment, team execution, people performance, and learning management solutions to organizations of all sizes across the globe. See more   Company Name Lumesse (formerly known as StepStone Solutions) Total Duration 4 yrs 1 mo Title Director, Sales and Business Development Dates Employed May 2011 – Oct 2012 Employment Duration 1 yr 6 mos Lumesse is the only global company that makes talent management solutions work locally. We help customers around the world to implement successful local talent management initiatives that identify, nurture and develop the right people, in the right place, at the right time. See more See more Title Regional Senior Business Development Manager Dates Employed Jul 2010 – May 2011 Employment Duration 11 mos Lumesse is one of the world’s leading suppliers of Total Talent Management Solutions, covering talent acquisition (e-recruitment) and talent management. StepStone Solutions works with over 1,400 customers in 40 countries worldwide. See more See more Title Senior Account Manager Dates Employed Oct 2008 – Jul 2010 Employment Duration 1 yr 10 mos -Familiar with software selling in China market -Provided training and coaching to business partners See more See more Show fewer roles , Title Director, Sales and Business Development Dates Employed May 2011 – Oct 2012 Employment Duration 1 yr 6 mos Lumesse is the only global company that makes talent management solutions work locally. We help customers around the world to implement successful local talent management initiatives that identify, nurture and develop the right people, in the right place, at the right time. See more See more   Company Name Lumesse (formerly known as StepStone Solutions) Total Duration 4 yrs 1 mo Title Director, Sales and Business Development Dates Employed May 2011 – Oct 2012 Employment Duration 1 yr 6 mos Lumesse is the only global company that makes talent management solutions work locally. We help customers around the world to implement successful local talent management initiatives that identify, nurture and develop the right people, in the right place, at the right time. See more See more Title Regional Senior Business Development Manager Dates Employed Jul 2010 – May 2011 Employment Duration 11 mos Lumesse is one of the world’s leading suppliers of Total Talent Management Solutions, covering talent acquisition (e-recruitment) and talent management. StepStone Solutions works with over 1,400 customers in 40 countries worldwide. See more See more Title Senior Account Manager Dates Employed Oct 2008 – Jul 2010 Employment Duration 1 yr 10 mos -Familiar with software selling in China market -Provided training and coaching to business partners See more See more Show fewer roles , Title Regional Senior Business Development Manager Dates Employed Jul 2010 – May 2011 Employment Duration 11 mos Lumesse is one of the world’s leading suppliers of Total Talent Management Solutions, covering talent acquisition (e-recruitment) and talent management. StepStone Solutions works with over 1,400 customers in 40 countries worldwide. See more See more   Company Name Lumesse (formerly known as StepStone Solutions) Total Duration 4 yrs 1 mo Title Director, Sales and Business Development Dates Employed May 2011 – Oct 2012 Employment Duration 1 yr 6 mos Lumesse is the only global company that makes talent management solutions work locally. We help customers around the world to implement successful local talent management initiatives that identify, nurture and develop the right people, in the right place, at the right time. See more See more Title Regional Senior Business Development Manager Dates Employed Jul 2010 – May 2011 Employment Duration 11 mos Lumesse is one of the world’s leading suppliers of Total Talent Management Solutions, covering talent acquisition (e-recruitment) and talent management. StepStone Solutions works with over 1,400 customers in 40 countries worldwide. See more See more Title Senior Account Manager Dates Employed Oct 2008 – Jul 2010 Employment Duration 1 yr 10 mos -Familiar with software selling in China market -Provided training and coaching to business partners See more See more Show fewer roles , Title Senior Account Manager Dates Employed Oct 2008 – Jul 2010 Employment Duration 1 yr 10 mos -Familiar with software selling in China market -Provided training and coaching to business partners See more See more   Sales Manager Company Name BroadLearning Education (Asia) Limited Dates Employed Jun 2002 – Sep 2008 Employment Duration 6 yrs 4 mos Technology company (eClass) focusing on eLearning and other peripherals Major clients: School (. ESF (English School Foundation)), Government (. Education Department Bureau), Corporate (. HWL, Olympus, Pizza Hut, MTR) See more See more   Head of Cloud Applications Company Name Oracle Dates Employed Feb 2018 – Present Employment Duration 1 yr 3 mos Location Hong Kong   Head of Cloud HCM Company Name SAP Dates Employed Sep 2015 – Feb 2018 Employment Duration 2 yrs 6 mos   Regional Sales Director Company Name SuccessFactors an SAP company Dates Employed Oct 2012 – Sep 2015 Employment Duration 3 yrs   Sales Manager Company Name BroadLearning Education (Asia) Limited Dates Employed Jun 2002 – Sep 2008 Employment Duration 6 yrs 4 mos   Company Name Lumesse (formerly known as StepStone Solutions) Total Duration 4 yrs 1 mo  The Chinese University of Hong Kong Field Of Study Practical Accounting and Financing   City University of Hong Kong Field Of Study eCommerce   City University of Hong Kong Field Of Study Information Systems  SaaS   Talent Management   Consulting   Direct Sales   Cloud Computing   CRM   Sales Management   Account Management   Recruiting   Sales   Professional Services   Solution Selling   Pre-sales   Employer Branding   Sales Process   ERP   Vendor Management   Customer Relationship Management (CRM)   Enterprise Resource Planning (ERP)   Market Development   Software Industry   Mobile Technology   Psychological Assessment   IT Solutions   Enterprise Software   HRIS   Software as a Service (SaaS)      Human Resources Information Systems (HRIS)   Learning Management Systems   SAP   Management   Strategic Partnerships   Business Alliances   Training   Personnel Management   Lead Generation   Networking   Social Recruiting   Complex Sales   Talent Acquisition   Selling   Partner Management  Industry Knowledge Direct Sales See 18 endorsements for Direct Sales 18 Cloud Computing See 14 endorsements for Cloud Computing 14 CRM See 12 endorsements for CRM 12 Sales Management See 10 endorsements for Sales Management 10 Account Management See 9 endorsements for Account Management 9 Recruiting See 9 endorsements for Recruiting 9 Sales See 8 endorsements for Sales 8 Professional Services See 5 endorsements for Professional Services 5 Solution Selling See 5 endorsements for Solution Selling 5 Pre-sales See 5 endorsements for Pre-sales 5 Employer Branding See 3 endorsements for Employer Branding 3 Sales Process See 3 endorsements for Sales Process 3 ERP See 2 endorsements for ERP 2 Vendor Management See 2 endorsements for Vendor Management 2 Customer Relationship Management (CRM) Customer Relationship Management (CRM) See 2 endorsements for Customer Relationship Management (CRM) 2 Enterprise Resource Planning (ERP) See 2 endorsements for Enterprise Resource Planning (ERP) 2 Market Development See 1 endorsement for Market Development 1 Software Industry See 1 endorsement for Software Industry 1 Mobile Technology Psychological Assessment IT Solutions   Tools & Technologies Enterprise Software See 17 endorsements for Enterprise Software 17 HRIS See 12 endorsements for HRIS 12 Software as a Service (SaaS) See 3 endorsements for Software as a Service (SaaS) 3  See 2 endorsements for  2 Human Resources Information Systems (HRIS) Human Resources Information Systems (HRIS) See 2 endorsements for Human Resources Information Systems (HRIS) 2 Learning Management Systems See 1 endorsement for Learning Management Systems 1 SAP See 1 endorsement for SAP 1   Interpersonal Skills Management See 20 endorsements for Management 20 Strategic Partnerships See 7 endorsements for Strategic Partnerships 7 Business Alliances See 5 endorsements for Business Alliances 5 Training See 5 endorsements for Training 5 Personnel Management See 3 endorsements for Personnel Management 3 Lead Generation See 3 endorsements for Lead Generation 3   Other Skills Networking See 4 endorsements for Networking 4 Social Recruiting See 1 endorsement for Social Recruiting 1 Complex Sales Talent Acquisition See 31 endorsements for Talent Acquisition 31 Selling See 4 endorsements for Selling 4 Partner Management See 3 endorsements for Partner Management 3 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAC5_XYG2OpN",
        "colab_type": "text"
      },
      "source": [
        "Different way to get similarity matrix \n",
        "\n",
        "1. spacy_tokenizer + genism(tfidf)\n",
        "\n",
        "**2. spacy_tokenizer + sklearn tfidfvectorizer + cosine similarity**\n",
        "\n",
        "3. spacy_tokenizer + spacy similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYDELQni9nyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = [(\" \").join(spacy_tokenizer(text)) for text in profile_df[\"profile_detail\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQCq5FtU9oQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Create the Document Term Matrix\n",
        "count_vectorizer = TfidfVectorizer()\n",
        "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
        "doc_term_matrix = sparse_matrix.todense()\n",
        "df = pd.DataFrame(doc_term_matrix, \n",
        "                  columns=count_vectorizer.get_feature_names(), \n",
        "                  index=profile_df[\"profile_name\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIMdIKYy9sQ5",
        "colab_type": "code",
        "outputId": "ebcd30f7-2ff6-40cd-a559-871d26cea5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>01</th>\n",
              "      <th>02002246</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>10118009</th>\n",
              "      <th>11</th>\n",
              "      <th>1100</th>\n",
              "      <th>111</th>\n",
              "      <th>11558293</th>\n",
              "      <th>11901698</th>\n",
              "      <th>11939</th>\n",
              "      <th>12</th>\n",
              "      <th>121</th>\n",
              "      <th>13</th>\n",
              "      <th>130</th>\n",
              "      <th>132</th>\n",
              "      <th>13d</th>\n",
              "      <th>14</th>\n",
              "      <th>140</th>\n",
              "      <th>15</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>1535</th>\n",
              "      <th>16</th>\n",
              "      <th>16293507</th>\n",
              "      <th>17</th>\n",
              "      <th>175</th>\n",
              "      <th>178b</th>\n",
              "      <th>18</th>\n",
              "      <th>180</th>\n",
              "      <th>1828</th>\n",
              "      <th>18345031</th>\n",
              "      <th>18351997</th>\n",
              "      <th>18603397</th>\n",
              "      <th>1898</th>\n",
              "      <th>19</th>\n",
              "      <th>1914246</th>\n",
              "      <th>193</th>\n",
              "      <th>1974641</th>\n",
              "      <th>...</th>\n",
              "      <th>xforcecolloboration</th>\n",
              "      <th>xgd</th>\n",
              "      <th>xi</th>\n",
              "      <th>xl8ys57czgyf</th>\n",
              "      <th>xml</th>\n",
              "      <th>xtradb</th>\n",
              "      <th>xu</th>\n",
              "      <th>yahoo</th>\n",
              "      <th>yale</th>\n",
              "      <th>yan</th>\n",
              "      <th>yasen</th>\n",
              "      <th>yat</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yi</th>\n",
              "      <th>yin</th>\n",
              "      <th>york</th>\n",
              "      <th>yosjdv</th>\n",
              "      <th>young</th>\n",
              "      <th>youngest</th>\n",
              "      <th>youth</th>\n",
              "      <th>youths</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yuan</th>\n",
              "      <th>yuilop</th>\n",
              "      <th>z01</th>\n",
              "      <th>zegal</th>\n",
              "      <th>zensoft</th>\n",
              "      <th>zhefei</th>\n",
              "      <th>zhejiang</th>\n",
              "      <th>zicklin</th>\n",
              "      <th>zjz</th>\n",
              "      <th>zone</th>\n",
              "      <th>zones</th>\n",
              "      <th>zwoop</th>\n",
              "      <th>zz</th>\n",
              "      <th>новосибирская</th>\n",
              "      <th>область</th>\n",
              "      <th>россия</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>profile_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Abby Tang</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035775</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035775</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036050</td>\n",
              "      <td>0.120167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ai Shinozaki</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dr Alan Chow MIET MIEEE MAUSIMM</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032717</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.057254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.051134</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027766</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036552</td>\n",
              "      <td>0.020785</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048072</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021979</td>\n",
              "      <td>0.120885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Abel Cheung</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065099</td>\n",
              "      <td>0.065099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ai autodata</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Xin LI</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315378</td>\n",
              "      <td>0.093136</td>\n",
              "      <td>0.079442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.105008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wong Loretta</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.047926</td>\n",
              "      <td>0.063902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worldmoney Blockchain News</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.354053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wayne Liu</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.087704</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074291</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.058920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ray (Wen Jie) LIEW</th>\n",
              "      <td>0.024151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024655</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016563</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4613 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       000   01  ...  область  россия\n",
              "profile_name                                     ...                 \n",
              " Abby Tang                        0.000000  0.0  ...      0.0     0.0\n",
              " Ai Shinozaki                     0.000000  0.0  ...      0.0     0.0\n",
              " Dr Alan Chow MIET MIEEE MAUSIMM  0.000000  0.0  ...      0.0     0.0\n",
              " Abel Cheung                      0.000000  0.0  ...      0.0     0.0\n",
              " ai autodata                      0.000000  0.0  ...      0.0     0.0\n",
              "...                                    ...  ...  ...      ...     ...\n",
              " Xin LI                           0.000000  0.0  ...      0.0     0.0\n",
              " Wong Loretta                     0.000000  0.0  ...      0.0     0.0\n",
              " Worldmoney Blockchain News       0.000000  0.0  ...      0.0     0.0\n",
              " Wayne Liu                        0.000000  0.0  ...      0.0     0.0\n",
              " Ray (Wen Jie) LIEW               0.024151  0.0  ...      0.0     0.0\n",
              "\n",
              "[100 rows x 4613 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQDue4vj9tkd",
        "colab_type": "code",
        "outputId": "23a97399-eac4-45b3-a97c-08b2fa54adba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Compute Cosine Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "sims_matrix = cosine_similarity(df, df)\n",
        "print(sims_matrix)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.01542482 0.20143616 ... 0.16799212 0.1476735  0.18518347]\n",
            " [0.01542482 1.         0.01511693 ... 0.01474565 0.0063966  0.02797098]\n",
            " [0.20143616 0.01511693 1.         ... 0.17325747 0.14803296 0.21950924]\n",
            " ...\n",
            " [0.16799212 0.01474565 0.17325747 ... 1.         0.08843764 0.16158089]\n",
            " [0.1476735  0.0063966  0.14803296 ... 0.08843764 1.         0.11285665]\n",
            " [0.18518347 0.02797098 0.21950924 ... 0.16158089 0.11285665 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV4UwQjTJqQu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_BetkpPXok9Z"
      },
      "source": [
        "Different way to get similarity matrix \n",
        "\n",
        "1. spacy_tokenizer + genism(tfidf)\n",
        "\n",
        "2. spacy_tokenizer + sklearn tfidfvectorizer + cosine similarity\n",
        "\n",
        "**3. spacy_tokenizer + spacy similarity**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjZmchX_fTEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2OU3dumHI9a",
        "colab_type": "code",
        "outputId": "dfb0b4f7-db7a-446f-ac99-71fad0c0cdee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "token1 = nlp(\"i love dog.\")\n",
        "token5 = nlp(\"i love dog\")\n",
        "token6 = nlp(\"dog love me.\")\n",
        "token2 = nlp(\"i love dog?\")\n",
        "token3 = nlp(\"i hate dog.\")\n",
        "token4 = nlp(\"cat love dog.\")\n",
        "token7 = nlp(\"rabbit like carrot.\")\n",
        "token1.similarity\n",
        "print(token1.vector_norm,token2.vector_norm,token3.vector_norm,token4.vector_norm,token5.vector_norm,token6.vector_norm,token7.vector_norm)\n",
        "# 4.431595721931874 4.507516618461838 4.391567403021321 4.6381735996661915 5.044537372524752 4.369449490570207 3.8596050346561275"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.431595721931874 4.507516618461838 4.391567403021321 4.6381735996661915 5.044537372524752 4.369449490570207 3.8596050346561275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL73YmmK_k85",
        "colab_type": "code",
        "outputId": "42cb62ce-9b40-4f54-cb86-4252579e026f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# get profile detail and tokenize them with spacy\n",
        "documents = [(\" \").join(spacy_tokenizer(text)) for text in profile_df[\"profile_detail\"]] \n",
        "\n",
        "target_profile = (\" \").join(spacy_tokenizer(target_profile))\n",
        "target_token = nlp(target_profile)\n",
        "\n",
        "sims_list = []\n",
        "i = 0\n",
        "for profile in documents:\n",
        "    profile_token = nlp(profile)\n",
        "    sims_list.append((i,profile_token.similarity(target_token)))\n",
        "    i += 1\n",
        "print(sims_list)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.619402740195683), (1, 0.96920621010979), (2, 0.6173353595051858), (3, 0.6025665768768006), (4, 0.3319581583953515), (5, 0.6005873206297402), (6, 0.5421640297279517), (7, 0.6655084826787423), (8, 0.5714591546394197), (9, 0.5855087389474363), (10, 0.5076313448834483), (11, 0.654229655352492), (12, 0.5482235219769287), (13, 0.5937380231184313), (14, 0.6404740515960193), (15, 0.5996352252452652), (16, 0.6208728553995376), (17, 0.5156269112564439), (18, 0.5780814876021051), (19, 0.6539198574169972), (20, 0.6371772941182153), (21, 0.5962243464937379), (22, 0.5452922446072018), (23, 0.6606592177945053), (24, 0.6528448487947502), (25, 0.6409972218834031), (26, 0.5842399998851424), (27, 0.41441893041531097), (28, 0.5130685138692994), (29, 0.6044389662431003), (30, 0.5787914821334269), (31, 0.5976204040187746), (32, 0.54852973592073), (33, 0.5686242101352627), (34, 0.6547948327343357), (35, 0.5929108779066831), (36, 0.611595633877019), (37, 0.6345778203418048), (38, 0.5870773889837978), (39, 0.6557239913772176), (40, 0.603030767913564), (41, 0.6291908694656919), (42, 0.655416434470732), (43, 0.5984771873071472), (44, 0.6033004940730039), (45, 0.6182281370407601), (46, 0.5991185719911216), (47, 0.6715514910912999), (48, 0.5328881650182681), (49, 0.6390578332319493), (50, 0.6661874643748352), (51, 0.5850373721515442), (52, 0.5997021003087833), (53, 0.6601266491477856), (54, 0.6050629399374302), (55, 0.5652847883790855), (56, 0.6612121279527069), (57, 0.6213853550424092), (58, 0.5281157950427477), (59, 0.5910798810295863), (60, 0.4668298469333621), (61, 0.0), (62, 0.6161614771924672), (63, 0.6165119209057873), (64, 0.4957133246588946), (65, 0.5902128734236285), (66, 0.0), (67, 0.6055006470424592), (68, 0.580088055386611), (69, 0.6304410747873761), (70, 0.6128399083822827), (71, 0.5247885780317605), (72, 0.5583047631093423), (73, 0.6289875495995138), (74, 0.5009377279808263), (75, 0.6498794730885675), (76, 0.5596873644639542), (77, 0.5294642150185481), (78, 0.6228722559660737), (79, 0.5890407534686493), (80, 0.6381913018072084), (81, 0.6715271776150367), (82, 0.672471352296247), (83, 0.5290782329923316), (84, 0.6534594925756819), (85, 0.6275143405596927), (86, 0.5274513797923152), (87, 0.5488383865093873), (88, 0.5649567431647528), (89, 0.5155809961434344), (90, 0.706554777487361), (91, 0.46691925211321794), (92, 0.5485827463353744), (93, 0.6418761100683027), (94, 0.6190766296346555), (95, 0.6271120876115415), (96, 0.671801147121337), (97, 0.5331858916381016), (98, 0.5767527831334537), (99, 0.6873498148382473)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D67k2vGrsFnD",
        "colab_type": "code",
        "outputId": "b9be69e2-ab70-49e9-e6f5-f82bfe057104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "sims_list = sorted(sims_list, key=lambda item: -item[1])\n",
        "print(sims_list)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 0.96920621010979), (90, 0.706554777487361), (99, 0.6873498148382473), (82, 0.672471352296247), (96, 0.671801147121337), (47, 0.6715514910912999), (81, 0.6715271776150367), (50, 0.6661874643748352), (7, 0.6655084826787423), (56, 0.6612121279527069), (23, 0.6606592177945053), (53, 0.6601266491477856), (39, 0.6557239913772176), (42, 0.655416434470732), (34, 0.6547948327343357), (11, 0.654229655352492), (19, 0.6539198574169972), (84, 0.6534594925756819), (24, 0.6528448487947502), (75, 0.6498794730885675), (93, 0.6418761100683027), (25, 0.6409972218834031), (14, 0.6404740515960193), (49, 0.6390578332319493), (80, 0.6381913018072084), (20, 0.6371772941182153), (37, 0.6345778203418048), (69, 0.6304410747873761), (41, 0.6291908694656919), (73, 0.6289875495995138), (85, 0.6275143405596927), (95, 0.6271120876115415), (78, 0.6228722559660737), (57, 0.6213853550424092), (16, 0.6208728553995376), (0, 0.619402740195683), (94, 0.6190766296346555), (45, 0.6182281370407601), (2, 0.6173353595051858), (63, 0.6165119209057873), (62, 0.6161614771924672), (70, 0.6128399083822827), (36, 0.611595633877019), (67, 0.6055006470424592), (54, 0.6050629399374302), (29, 0.6044389662431003), (44, 0.6033004940730039), (40, 0.603030767913564), (3, 0.6025665768768006), (5, 0.6005873206297402), (52, 0.5997021003087833), (15, 0.5996352252452652), (46, 0.5991185719911216), (43, 0.5984771873071472), (31, 0.5976204040187746), (21, 0.5962243464937379), (13, 0.5937380231184313), (35, 0.5929108779066831), (59, 0.5910798810295863), (65, 0.5902128734236285), (79, 0.5890407534686493), (38, 0.5870773889837978), (9, 0.5855087389474363), (51, 0.5850373721515442), (26, 0.5842399998851424), (68, 0.580088055386611), (30, 0.5787914821334269), (18, 0.5780814876021051), (98, 0.5767527831334537), (8, 0.5714591546394197), (33, 0.5686242101352627), (55, 0.5652847883790855), (88, 0.5649567431647528), (76, 0.5596873644639542), (72, 0.5583047631093423), (87, 0.5488383865093873), (92, 0.5485827463353744), (32, 0.54852973592073), (12, 0.5482235219769287), (22, 0.5452922446072018), (6, 0.5421640297279517), (97, 0.5331858916381016), (48, 0.5328881650182681), (77, 0.5294642150185481), (83, 0.5290782329923316), (58, 0.5281157950427477), (86, 0.5274513797923152), (71, 0.5247885780317605), (17, 0.5156269112564439), (89, 0.5155809961434344), (28, 0.5130685138692994), (10, 0.5076313448834483), (74, 0.5009377279808263), (64, 0.4957133246588946), (91, 0.46691925211321794), (60, 0.4668298469333621), (27, 0.41441893041531097), (4, 0.3319581583953515), (61, 0.0), (66, 0.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awY_WzeEs0CC",
        "colab_type": "code",
        "outputId": "2ce35dfd-fd74-47fa-c188-856de6af82c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "print(\"Top 5 similar profile: \")\n",
        "for each in sims_list[0:5]:\n",
        "    print(each,profile_df[\"profile_detail\"][each[0]])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 5 similar profile: \n",
            "(1, 0.96920621010979) My nick name is Ai Shinozaki. I am a PG Girl Show. I can make Sexy Walk show, Sexy Face Funny Show or whatever, I can speak Japanese, Mandarin and English. I love food, sports, music, movies. I like to travel and picnic to different countries.  My nick name is Ai Shinozaki. I am a PG Girl Show. I can make Sexy Walk show, Sexy Face Funny Show or whatever, I can speak Japanese, Mandarin and English. I love food, sports, music, movies. I like to travel and picnic to different countries.  PG Model Company Name ABC PG Model Dates Employed Feb 2012 – Present Employment Duration 7 yrs 3 mos  Target Orientation   Reading Comprehension   Speaking Comprehension   Sexy PG Show   Sexy Girl Face & Body   Sexy Walk Show  Other Skills Sexy PG Show Sexy Girl Face & Body Sexy Walk Show \n",
            "(90, 0.706554777487361) Mr. Shiu was the Senior Editor of Sing Tao Daily’s IT supplement, “PC Market” before he co-founded Linux Pilot Ltd. A veteran in IT news, editorials and reporting, he maintains a good network of industry leaders. Understanding the significance of Linux and Open Source technologies, he co-founded Linux Pilot Limited. He is in charge of research and editorials of Linux Pilot Limited, BQ Journal, HK-, . As the co-Chairman of HK SME Forum, Mr. Shiu has helped many SME to use eMarketing and eCommerce to expand their business in mainland China. He is a Master Degree holder in Journalism and Communication of the Chinese University of Hong Kong. Since 2015 July, Mr. Shiu is appointed as the Digital Marketing Consultant of Shenzhen Time e-Supply Chain Management Co., Ltd. (Time Steel Supermarket) is a large steel-industry specialized international trading e-commerce platform. From 2016 February, Mr. Shiu is appointed as the General Manager of Information Technology of Shenzhen Time e-Supply Chain Management Co., 2015720162 Show less Show less of Vincent’s summary  Mr. Shiu was the Senior Editor of Sing Tao Daily’s IT supplement, “PC Market” before he co-founded Linux Pilot Ltd. A veteran in IT news, editorials and reporting, he maintains a good network of industry leaders. Understanding the significance of Linux and Open Source technologies, he co-founded Linux Pilot Limited. He is in charge of research and editorials of Linux Pilot Limited, BQ Journal, HK-, . As the co-Chairman of HK SME Forum, Mr. Shiu has helped many SME to use eMarketing and eCommerce to expand their business in mainland China. He is a Master Degree holder in Journalism and Communication of the Chinese University of Hong Kong. Since 2015 July, Mr. Shiu is appointed as the Digital Marketing Consultant of Shenzhen Time e-Supply Chain Management Co., Ltd. (Time Steel Supermarket) is a large steel-industry specialized international trading e-commerce platform. From 2016 February, Mr. Shiu is appointed as the General Manager of Information Technology of Shenzhen Time e-Supply Chain Management Co., 2015720162  Senior Editor Company Name Sing Tao Daily Dates Employed 1994 – 1999 Employment Duration 5 yrs   Director Company Name Linux Pilot Limited Dates Employed 1999 – Present Employment Duration 20 yrs Location Hong Kong  The Chinese University of Hong Kong Degree Name Master's degree Field Of Study Communication and Media Studies Grade A Dates attended or expected graduation 1999 – 2001 Activities and Societies: Christian Fellowship   Kwun Tong Maryknoll College Degree Name High School Field Of Study Liberal Arts and Sciences/Liberal Studies Grade A Dates attended or expected graduation 1984 – 1989 Activities and Societies: Geography Club   Helper Company Name Yan Kwong Social Service Centre Dates volunteered Feb 2015 Volunteer duration 1 mo Cause Social Services   Helper on Dr. Elsie Tu Centenary Birthday Celebration Company Name Mu Kuang English School Alumni Dates volunteered Jun 2013 Volunteer duration 1 mo Cause Education \n",
            "(99, 0.6873498148382473) Ray Liew is the Data and AI solution specialist at Microsoft Hong Kong. He is responsible for driving commercial Data and AI scenarios, which includes Advanced Forecasting, Predictive Maintenance and Customer 360 across different sectors in Hong Kong. Prior to his current role, he was an Account Manager at Meltwater, a news and social media analytics company where he managed a portfolio of 65 clients, helping them make better, more informed decisions based on insights from online data. Ray has also spent half his life abroad; Having studied in Hong Kong and Singapore, he leverages on his diverse background and Malaysian roots to enable Digital Transformation across  from being a technology geek, Ray has a strong passion for fitness and sports and preaches the concept integrating fitness as a lifestyle to his peers and juniors. Ray holds a double major in Global Business and Information Systems from the Hong Kong University of Science and Technology and was the Head Student Ambassador during his time at university. Show less Show less of Ray (Wen Jie)’s summary  Ray Liew is the Data and AI solution specialist at Microsoft Hong Kong. He is responsible for driving commercial Data and AI scenarios, which includes Advanced Forecasting, Predictive Maintenance and Customer 360 across different sectors in Hong Kong. Prior to his current role, he was an Account Manager at Meltwater, a news and social media analytics company where he managed a portfolio of 65 clients, helping them make better, more informed decisions based on insights from online data. Ray has also spent half his life abroad; Having studied in Hong Kong and Singapore, he leverages on his diverse background and Malaysian roots to enable Digital Transformation across  from being a technology geek, Ray has a strong passion for fitness and sports and preaches the concept integrating fitness as a lifestyle to his peers and juniors. Ray holds a double major in Global Business and Information Systems from the Hong Kong University of Science and Technology and was the Head Student Ambassador during his time at university.  Data and AI Solution Specialist (SSP) Company Name Microsoft Dates Employed Feb 2018 – Present Employment Duration 1 yr 3 mos Location Hong Kong We believe in what people make possible. Our mission is to empower every person and every organisation on the planet to achieve more. See more Microsoft AI Commercial Featuring Common Microsoft AI Commercial Featurin   Account Manager Company Name Meltwater Dates Employed Jul 2017 – Feb 2018 Employment Duration 8 mos Location Hong Kong Meltwater helps companies make better, more informed decisions based on insights from the outside. We believe that business strategy will be increasingly shaped by insights from online data. More than 25,000 companies use the Meltwater media intelligence platform to stay on top of billions of online conversations, extract relevant real-time insights, and use them to See more See more   Client Success Intern Company Name Meltwater Dates Employed Jun 2016 – Aug 2016 Employment Duration 3 mos Location Hong Kong As a Client Success Intern, my duties and accomplishments included but were not limited to: – Learnt and executed the Meltwater Sales Methodology; experiencing the full tech sales cycle, whilst engaging with C-Level Executives, driving strong value propositions for their cu See more See more   HKUST Chapter - Co-founder & Strategic Partnerships Director Company Name 180 Degrees Consulting Dates Employed Aug 2015 – Jun 2016 Employment Duration 11 mos Location Hong Kong 180 Degrees provides socially conscious organizations around the world with very high quality, extremely affordable consulting services. We work with organizations to develop innovative, practical and sustainable solutions to whatever challenges they’re facing. As such, 180 Degrees connects the untapped capabilities of university students with the unmet needs of so See more See more   Bank-Wide Operations Intern Company Name Bank of China (Hong Kong) Dates Employed Jun 2015 – Aug 2015 Employment Duration 3 mos Location Hong Kong – Executed various different types of mortgage loans on a daily basis and learnt the whole process and operations involved in executing a mortgage loan – Conducted due diligence for 20 mortgage cases daily, involving mortgage agreements for both individuals and SMEs in the Hong Kong region See more See more   Accounting Intern Company Name Lam Seng Plastics Sdn. Bhd. Dates Employed Mar 2013 – Jun 2013 Employment Duration 4 mos Location Kuala Lumpur, Malaysia Lam Seng Plastics Industries Sdn Bhd (LSP) is a Malaysia plastic products and plastic household ware manufacturer offering high quality plastic ware for the home and industrial use. We are also a plastic OEM manufacturer specializes in plastic packaging, household wares, and industrial containers See more See more Malaysia Plastic Products Household Wares Manufacturer Malaysia Plastic Products Household   Data and AI Solution Specialist (SSP) Company Name Microsoft Dates Employed Feb 2018 – Present Employment Duration 1 yr 3 mos Location Hong Kong   Account Manager Company Name Meltwater Dates Employed Jul 2017 – Feb 2018 Employment Duration 8 mos Location Hong Kong   Client Success Intern Company Name Meltwater Dates Employed Jun 2016 – Aug 2016 Employment Duration 3 mos Location Hong Kong   HKUST Chapter - Co-founder & Strategic Partnerships Director Company Name 180 Degrees Consulting Dates Employed Aug 2015 – Jun 2016 Employment Duration 11 mos Location Hong Kong   Bank-Wide Operations Intern Company Name Bank of China (Hong Kong) Dates Employed Jun 2015 – Aug 2015 Employment Duration 3 mos Location Hong Kong   Accounting Intern Company Name Lam Seng Plastics Sdn. Bhd. Dates Employed Mar 2013 – Jun 2013 Employment Duration 4 mos Location Kuala Lumpur, Malaysia  HKUST Business School Degree Name Bachelor of Business Administration (BBA) in Global Business, Information Systems & Entrepreneurship Dates attended or expected graduation 2013 – 2017 Activities and Societies: Head Student Ambassador, Dragon Boat Team, Business Cohort Community (Cohort Chief) and Residential College Mentor   WHU – Otto Beisheim School of Management Degree Name Bachelor of Science (BSc) Field Of Study Entrepreneurship/Entrepreneurial Studies Dates attended or expected graduation 2016 – 2016   SJI International Degree Name IB Diploma Program Grade 42/45 Dates attended or expected graduation 2011 – 2012 Activities and Societies: Badminton Team (Captain), School Choir, Volunteer at Lee Ah Mo Old Folks Home and Gift of Love and an occasional break dancer   Group Leader & International Volunteer Company Name Chres Village School and Orphanage, Cambodia Dates volunteered Oct 2011 Volunteer duration 1 mo Cause Children   Student Volunteer Company Name Sri KDU Secondary School, Malaysia Dates volunteered Mar 2009 Volunteer duration 1 mo Cause Education  Insight Selling Issued date and, if applicable, expiration date of the certification or license Issued Oct 2018No Expiration Date \n",
            "(82, 0.672471352296247) I'm the founder of Raven Protocol where I work on bringing the power of AI development to the masses via decentralization. As a Partner at , I focus on funding AI and blockchain companies. Previously, I founded  and . I have been doing machine learning since 2008 and scaled Yahoo’s content platform to 600M users. My writing has appeared on Forbes, Huffington Post, and Business  me here: to Achain, Volareo, and absolutely love meeting founders working on AI & Blockchain. Show less Show less of Sherman’s summary  I'm the founder of Raven Protocol where I work on bringing the power of AI development to the masses via decentralization. As a Partner at , I focus on funding AI and blockchain companies. Previously, I founded  and . I have been doing machine learning since 2008 and scaled Yahoo’s content platform to 600M users. My writing has appeared on Forbes, Huffington Post, and Business  me here: to Achain, Volareo, and absolutely love meeting founders working on AI & Blockchain.  Mentor Company Name Manos Accelerator, LLC Dates Employed Aug 2013 – Dec 2013 Employment Duration 5 mos Location San Jose, California, USA - Advised startups on customer development, user acquisition, product design and execution. - Partnered with Google to accelerate startups in US and international markets. See more   Editor in Chief Company Name Good Sense Dates Employed Dec 2012 – Aug 2013 Employment Duration 9 mos Location San Francisco Bay Area - Empowering the freelance developer community -  See more Most Meetings Are Just 'Power-Plays' In Disguise Most Meetings Are Just 'Power-Plays' In How Bossing People Around Backfires How Bossing People Around Backfires   Director, Product Management and User Experience Company Name Superb Dates Employed Jan 2012 – Dec 2012 Employment Duration 12 mos Location San Francisco Bay Area - Co-founder of the on-demand car repair service - Did customer development at every SF gas station - Dialed in on problems drivers were willing to pay to have solved - Partnered with mechanics and acquired paying customers See more See more   Company Name Yahoo! Total Duration 4 yrs 8 mos Title Sr. Product Manager Dates Employed Jan 2011 – Jan 2012 Employment Duration 1 yr 1 mo Location Sunnyvale, California, USA - Product lead in the Special Projects group of Yahoo! Search - Initiated innovation projects aimed at the global product line for web search - Drove execution across global teams in engineering, research and design - Led a team of scientists to integrate their research into products as Head of Science See more Title Software Engineer Dates Employed Jun 2007 – Dec 2010 Employment Duration 3 yrs 7 mos Location Sunnyvale, California, USA - Engineering lead on Yahoo's Content Platform serving hundreds of sites today - Scaled it from 0 to 600M users - Hadoop for cloud computing and storage - Machine learning and data mining to enrich content See more See more , Title Sr. Product Manager Dates Employed Jan 2011 – Jan 2012 Employment Duration 1 yr 1 mo Location Sunnyvale, California, USA - Product lead in the Special Projects group of Yahoo! Search - Initiated innovation projects aimed at the global product line for web search - Drove execution across global teams in engineering, research and design - Led a team of scientists to integrate their research into products as Head of Science See more   Company Name Yahoo! Total Duration 4 yrs 8 mos Title Sr. Product Manager Dates Employed Jan 2011 – Jan 2012 Employment Duration 1 yr 1 mo Location Sunnyvale, California, USA - Product lead in the Special Projects group of Yahoo! Search - Initiated innovation projects aimed at the global product line for web search - Drove execution across global teams in engineering, research and design - Led a team of scientists to integrate their research into products as Head of Science See more Title Software Engineer Dates Employed Jun 2007 – Dec 2010 Employment Duration 3 yrs 7 mos Location Sunnyvale, California, USA - Engineering lead on Yahoo's Content Platform serving hundreds of sites today - Scaled it from 0 to 600M users - Hadoop for cloud computing and storage - Machine learning and data mining to enrich content See more See more , Title Software Engineer Dates Employed Jun 2007 – Dec 2010 Employment Duration 3 yrs 7 mos Location Sunnyvale, California, USA - Engineering lead on Yahoo's Content Platform serving hundreds of sites today - Scaled it from 0 to 600M users - Hadoop for cloud computing and storage - Machine learning and data mining to enrich content See more See more   Software Engineer Company Name  Dates Employed Jun 2006 – Jun 2007 Employment Duration 1 yr 1 mo Location Oakland, California, USA - Engineering lead at the former AskJeeves - Data Warehouse using Oracle Rack for storage - Frontend and backend development on Local and Maps products - Statistical learning for content enrichment See more   Software Engineer Intern Company Name Yahoo! Dates Employed May 2005 – Aug 2005 Employment Duration 4 mos Location Sunnyvale, California, USA - Engineering and product lead on Yahoo! Code Search - Developed and evangelized the entire application from concept to launch - Created custom indexing and crawled open source code repositories See more   Co-founder Company Name Raven Protocol Dates Employed Nov 2017 – Present Employment Duration 1 yr 6 mos Location Hong Kong   Partner Company Name  Dates Employed Jan 2018 – Present Employment Duration 1 yr 4 mos Location Hong Kong   Co-founder ( Batch #Z01) Company Name Rocco AI Dates Employed Nov 2016 – Present Employment Duration 2 yrs 6 mos Location San Francisco Bay Area and Hong Kong   Co-founder (Techstars London 2014) Company Name Good Audience Dates Employed Aug 2013 – Present Employment Duration 5 yrs 9 mos Location San Francisco Bay Area   Mentor Company Name Manos Accelerator, LLC Dates Employed Aug 2013 – Dec 2013 Employment Duration 5 mos Location San Jose, California, USA   Editor in Chief Company Name Good Sense Dates Employed Dec 2012 – Aug 2013 Employment Duration 9 mos Location San Francisco Bay Area   Director, Product Management and User Experience Company Name Superb Dates Employed Jan 2012 – Dec 2012 Employment Duration 12 mos Location San Francisco Bay Area   Software Engineer Company Name  Dates Employed Jun 2006 – Jun 2007 Employment Duration 1 yr 1 mo Location Oakland, California, USA   Software Engineer Intern Company Name Yahoo! Dates Employed May 2005 – Aug 2005 Employment Duration 4 mos Location Sunnyvale, California, USA   Company Name Yahoo! Total Duration 4 yrs 8 mos  University of California, Berkeley Degree Name Bachelors Field Of Study Computer Science and Linguistics Activities and Societies: Upsilon Pi Epsilon, Computer Science Undergraduate Association  Applesoft BASIC   User Experience   Ruby on Rails \n",
            "(96, 0.671801147121337)   Company Name Google Total Duration 4 yrs 3 mos Title Territory Sales Manager (Hong Kong), Google Cloud Dates Employed 2018 – Present Employment Duration 1 yr Location Singapore Brings Google Cloud to Hong Hong and helps companies modernize their infrastructure and solve business challenges See more A cloud made for Hong Kong A cloud made for Hong Kong Title Google Cloud for Startups Program Lead (HK) Dates Employed Sep 2018 – Present Employment Duration 8 mos Location Singapore Launches Google Cloud for Startups Programme in HK See more Title Key Account Manager Dates Employed Feb 2015 – Jun 2018 Employment Duration 3 yrs 5 mos Location Hong Kong Manages top tier clients in the Greater China region, helps brands digitize their business & grow online presence. Fosters c-level relationships and organizes industry workshops for marketers. Key verticals: e-commerce, retail, travel See more See more , Title Territory Sales Manager (Hong Kong), Google Cloud Dates Employed 2018 – Present Employment Duration 1 yr Location Singapore Brings Google Cloud to Hong Hong and helps companies modernize their infrastructure and solve business challenges See more A cloud made for Hong Kong A cloud made for Hong Kong   Company Name Google Total Duration 4 yrs 3 mos Title Territory Sales Manager (Hong Kong), Google Cloud Dates Employed 2018 – Present Employment Duration 1 yr Location Singapore Brings Google Cloud to Hong Hong and helps companies modernize their infrastructure and solve business challenges See more A cloud made for Hong Kong A cloud made for Hong Kong Title Google Cloud for Startups Program Lead (HK) Dates Employed Sep 2018 – Present Employment Duration 8 mos Location Singapore Launches Google Cloud for Startups Programme in HK See more Title Key Account Manager Dates Employed Feb 2015 – Jun 2018 Employment Duration 3 yrs 5 mos Location Hong Kong Manages top tier clients in the Greater China region, helps brands digitize their business & grow online presence. Fosters c-level relationships and organizes industry workshops for marketers. Key verticals: e-commerce, retail, travel See more See more , Title Google Cloud for Startups Program Lead (HK) Dates Employed Sep 2018 – Present Employment Duration 8 mos Location Singapore Launches Google Cloud for Startups Programme in HK See more   Company Name Google Total Duration 4 yrs 3 mos Title Territory Sales Manager (Hong Kong), Google Cloud Dates Employed 2018 – Present Employment Duration 1 yr Location Singapore Brings Google Cloud to Hong Hong and helps companies modernize their infrastructure and solve business challenges See more A cloud made for Hong Kong A cloud made for Hong Kong Title Google Cloud for Startups Program Lead (HK) Dates Employed Sep 2018 – Present Employment Duration 8 mos Location Singapore Launches Google Cloud for Startups Programme in HK See more Title Key Account Manager Dates Employed Feb 2015 – Jun 2018 Employment Duration 3 yrs 5 mos Location Hong Kong Manages top tier clients in the Greater China region, helps brands digitize their business & grow online presence. Fosters c-level relationships and organizes industry workshops for marketers. Key verticals: e-commerce, retail, travel See more See more , Title Key Account Manager Dates Employed Feb 2015 – Jun 2018 Employment Duration 3 yrs 5 mos Location Hong Kong Manages top tier clients in the Greater China region, helps brands digitize their business & grow online presence. Fosters c-level relationships and organizes industry workshops for marketers. Key verticals: e-commerce, retail, travel See more See more   Administrative Officer (AO) Company Name HKSAR Government Dates Employed Jul 2013 – Dec 2014 Employment Duration 1 yr 6 mos Location Central Government Officers, Tamar, Hong Kong - Commerce and Economic Development Bureau (July 2012 - March 2014) - Food and Health Bureau (March  December 2014) Formulated government policies on export/import and food safety areas, stakeholders See more See more   Summer Internship Company Name John Swire & Sons (.) Ltd. Dates Employed Jul 2011 – Aug 2011 Employment Duration 2 mos   Winter Internship Company Name HSBC Dates Employed Dec 2010 – Feb 2011 Employment Duration 3 mos Location HK   Administrative Officer (AO) Company Name HKSAR Government Dates Employed Jul 2013 – Dec 2014 Employment Duration 1 yr 6 mos Location Central Government Officers, Tamar, Hong Kong   Company Name Google Total Duration 4 yrs 3 mos  The University of Hong Kong Degree Name Bachelor of Business Administration (BBA) Field Of Study International Business and Global Management; Human Resources Management Dates attended or expected graduation 2009 – 2012 Activities and Societies: Business and Economics Association HKUSU   WU (Vienna University of Economics and Business) Field Of Study International Business   St. Mary's Canossian College  Marketing Strategy   Search Engine Technology   English   Business Strategy   Research   Business Development   E-commerce   Start-ups   Strategy   Marketing   Microsoft Office   Microsoft Excel   PowerPoint   Microsoft Word   Mandarin   Chinese   Cantonese  Industry Knowledge Business Strategy See 3 endorsements for Business Strategy 3 Research See 2 endorsements for Research 2 Business Development See 1 endorsement for Business Development 1 E-commerce Start-ups Strategy Marketing   Tools & Technologies Microsoft Office See 7 endorsements for Microsoft Office 7 Microsoft Excel See 5 endorsements for Microsoft Excel 5 PowerPoint See 3 endorsements for PowerPoint 3 Microsoft Word See 3 endorsements for Microsoft Word 3   Languages Mandarin See 3 endorsements for Mandarin 3 Chinese See 2 endorsements for Chinese 2   Other Skills Cantonese See 4 endorsements for Cantonese 4 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJuERy2ks4ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}